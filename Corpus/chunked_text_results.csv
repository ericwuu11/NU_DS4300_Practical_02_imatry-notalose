Chunk 200 | Overlap 0,Chunk 200 | Overlap 50,Chunk 200 | Overlap 100,Chunk 500 | Overlap 0,Chunk 500 | Overlap 50,Chunk 500 | Overlap 100,Chunk 1000 | Overlap 0,Chunk 1000 | Overlap 50,Chunk 1000 | Overlap 100
ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single,ds 4300 large scale information storage and retrieval foundations mark fontenot phd northeastern university searching searching is the most common operation performed by a database system in sql the select statement is arguably the most versatile complex baseline for efficiency is linear search start at the beginning of a list and proceed element by element until you find what youre looking for you get to the last element and havent found it searching record a collection of values for attributes of a single entity instance a row of a table collection a set of records of the same entity type a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single
6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in,list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p,a table trivially stored in some sequential order like a list search key a value for an attribute from the entity type could be 1 attribute lists of records if each record takes up x bytes of memory then for n records we need nx bytes of memory contiguously allocated list all nx bytes are allocated as a single chunk of memory linked list each record needs x bytes additional space for 1 or 2 memory addresses individual records are linked together in a type of chain using memory addresses contiguous vs linked 6 records contiguously allocated array front back 6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index,specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single,complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in,the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all,transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the,dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions,data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok
the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array,of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and,6 records linked by memory addresses linked list extra storage for a memory address pros and cons arrays are faster for random access but slow for inserting anywhere but the end linked lists are faster for inserting anywhere in the list but slower for random access insert after 2nd record records records 5 records had to be moved to make space insert after 2nd record observations arrays fast for random access slow for random insertions linked lists slow for random access fast for random insertions binary search input array of values in sorted order target value output the location index of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in,transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the,data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of,storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps,leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems,for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always,availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the
of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented,complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by,of where target is located or some value indicating target was not found def binary_searcharr target left right 0 lenarr 1 while left right mid left right 2 if arrmid target return mid elif arrmid target left mid 1 else right mid 1 return 1 a c g m p r z target a mid since target arrmid we reset right to mid 1 left right a c g m p r z target a mid left right time complexity linear search best case target is found at the first element only 1 comparison worst case target is not in the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and,cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the,really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading,receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may,base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends,system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one,transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of
storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single,of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented,the array n comparisons therefore in the worst case linear search is on time complexity binary search best case target is found at mid 1 comparison inside the loop worst case target is not in the array log2 n comparisons therefore in the worst case binary search is olog2n time complexity back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array,leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with,availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the,tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the,lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a,basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the
transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values,second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in,specialval at the same time data would have to be duplicated space inefficient back to database searching assume data is stored on disk by column ids value searching for a specific id fast but what if we want to search for a specific specialval only option is linear scan of that column cant store data on disk sorted by both id and specialval at the same time data would have to be duplicated space inefficient we need an external data structure to support faster searching by specialval than a linear scan what do we have in our arsenal an array of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its,thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems,lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational,leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with,search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in,we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is,up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would
receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of,data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id,of tuples specialval rownumber sorted by specialval we could use binary search to quickly locate a particular specialval and find its corresponding row in the table but every insert into the table would be like inserting into a sorted array slow a linked list of tuples specialval rownumber sorted by specialval searching for a specialval would be slow linear scan required but inserting into the table would theoretically be quick to also add to the list something with fast insert and fast search binary search tree a binary tree where every node in the left subtree is less than its parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented,base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make,transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model,they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always,a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done,purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an,the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are
distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition,create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book,parent and every node in the right subtree is greater than its parent image from httpscoursesgraingerillinoiseducs225sp2019notesbst to the board ds 4300 moving beyond the relational model mark fontenot phd northeastern university benefits of the relational model mostly standard data model and query language acid compliance more on this in a second atomicity consistency isolation durability works well will highly structured data can handle large amounts of data well understood lots of tooling lots of experience relational database performance many ways that a rdbms increases efficiency indexing the topic we focused on directly controlling storage column oriented storage vs row oriented storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all,sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends,on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by,event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but,recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with,of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their,node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is
tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high,receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of,storage query optimization cachingprefetching materialized views precompiled stored procedures data replication and partitioning transaction processing transaction a sequence of one or more of the crud operations performed as a single logical unit of work either the entire sequence succeeds commit or the entire sequence fails rollback or abort help ensure data integrity error recovery concurrency control reliable data storage simplified error handling acid properties atomicity transaction is treated as an atomic unit it is fully executed or no parts of it are executed consistency a transaction takes a database from one consistent state to another consistent state consistent state all data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single,lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end,basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care,for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of,smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the
availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the,really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the,data meets integrity constraints acid properties isolation two transactions t1 and t2 are being executed at the same time but cannot affect each other if both t1 and t2 are reading the data no problem if t1 is reading the same data that t2 may be writing can result in dirty read nonrepeatable read phantom reads isolation dirty read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained dirty read a transaction t1 is able to read a row that has been modified by another transaction t2 that hasnt yet executed a commit isolation nonrepeatable read figure from httpswwwmybluelinuxcomrelationaldatabasesexplained nonrepeatable read two queries in a single transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id,up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential,basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care,,,at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77
leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader,cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may,transaction t1 execute a select but get different values because another transaction t2 has changed data and committed isolation phantom reads figure from httpswwwmybluelinuxcomrelationaldatabasesexplained phantom reads when a transaction t1 is running and another transaction t2 adds or deletes rows from the set t1 is using example transaction transfer delimiter create procedure transfer in sender_id int in receiver_id int in amount decimal102 begin declare rollback_message varchar255 default transaction rolled back insufficient funds declare commit_message varchar255 default transaction committed successfully start the transaction start transaction attempt to debit money from account 1 update accounts set balance balance amount where account_id sender_id attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values,search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would,up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end,,,
to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads,request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading,attempt to credit money to account 2 update accounts set balance balance amount where account_id receiver_id continued next slide example transaction transfer continued from previous slide check if there are sufficient funds in account 1 simulate a condition where there are insufficient funds if select balance from accounts where account_id sender_id 0 then roll back the transaction if there are insufficient funds rollback signal sqlstate 45000 45000 is unhandled userdefined error set message_text rollback_message else log the transactions if there are sufficient funds insert into transactions account_id amount transaction_type values sender_id amount withdrawal insert into transactions account_id amount transaction_type values receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps,still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in,binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics,right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be,,,
they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because,availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the,receiver_id amount deposit commit the transaction commit select commit_message as result end if end delimiter acid properties durability once a transaction is completed and committed successfully its changes are permanent even in the event of a system failure committed transactions are preserved for more info on transactions see kleppmann book chapter 7 but relational databases may not be the solution to all problems sometimes schemas evolve over time not all apps may need the full strength of acid compliance joins can be expensive a lot of data is semistructured or unstructured json xml etc horizontal scaling presents challenges some apps need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of,a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember,the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees,way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would,,,
it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the,have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost,need something more performant real time low latency systems scalability up or out conventional wisdom scale vertically up with bigger more powerful systems until the demands of highavailability make it necessary to scale out with some type of distributed computing model but why scaling up is easier no need to really modify your architecture but there are practical and financial limits however there are modern systems that make horizontal scaling less problematic so what distributed data when scaling out a distributed system is a collection of independent computers that appear to its users as one computer andrew tennenbaum characteristics of distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the,that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done,binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering,there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our,,,
event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems,most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the,distributed systems computers operate concurrently computers fail independently no shared global clock distributed storage 2 directions single main node distributed data stores data is stored on 1 node typically replicated ie each block of data is available on n nodes distributed databases can be relational or nonrelational mysql and postgresql support replication and sharding cockroachdb new player on the scene many nosql systems support one or both models but remember network partitioning is inevitable network failures system failures overall system needs to be partition tolerant system can keep running even w network partition the cap theorem the cap theorem the cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition,recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary,node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search,result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty,,,
base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model,lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain,cap theorem states that it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees consistency every read receives the most recent write or error thrown availability every request receives a nonerror response but no guarantee that the response contains the most recent write partition tolerance the system can continue to operate despite arbitrary network issues cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may,search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with,how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an,a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember,,,
for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually,they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because,tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem database view reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network issues consistency partition tolerance if system responds with data from a distributed store it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high,smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of,a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022,,,
strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial,is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational,not be the absolute latest data cap in reality what it is really saying if you cannot limit the number of faults requests can be directed to any server and you insist on serving every request then you cannot possibly be consistent but it is interpreted as you must always give up something consistency availability or tolerance to failure ds 4300 replicating data mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributing data benefits scalability high throughput data volume or readwrite load grows beyond the capacity of a single machine fault tolerance high availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok,,work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh,tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is,,,
basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history,transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always,availability your application needs to continue working even if one or more machines goes down latency when you have users in different parts of the world you want to give them fast performance too distributed data challenges consistency updates must be propagated across the network application complexity responsibility for reading and writing data in a distributed environment often falls to the application vertical scaling shared memory architectures geographically centralized server some fault tolerance via hotswappable components vertical scaling shared disk architectures machines are connected via a fast network contention and the overhead of locking limit scalability highwrite volumes but ok for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the,,at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of,,,
in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends,system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a,for data warehouse applications high read volumes aws ec2 pricing oct 2024 78000month httpsawsamazoncomec2pricingondemand horizontal scaling shared nothing architectures each node has its own cpu memory and disk coordination via application layer using conventional network geographically distributed commodity hardware data replication vs partitioning replicates have same data as main partitions have a subset of the data replication common strategies for replication single leader model multiple leader model leaderless model distributed databases usually adopt one of these strategies leaderbased replication all writes from clients go to the leader leader sends replication info to the followers followers process the instructions from the leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the,,,olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is,,,
lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6,base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model,leader clients can read from either the leader or followers leaderbased replication this write could not be sent to one of the followers only the leader leaderbased replication very common strategy relational mysql oracle sql server postgresql nosql mongodb rethinkdb realtime web apps espresso linkedin messaging brokers kafka rabbitmq how is replication info transmitted to followers synchronous vs asynchronous replication synchronous leader waits for a response from the follower asynchronous leader doesnt wait for confirmation synchronous asynchronous what happens when the leader fails challenges how do we pick a new leader node consensus strategy perhaps based on who has the most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader,,,smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,,,
and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the,on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a,most updates use a controller node to appoint new leader and how do we configure clients to start writing to the new leader what happens when the leader fails more challenges if asynchronous replication is used new leader may not have all the writes how do we recover the lost writes or do we simply discard after if the old leader recovers how do we avoid having multiple leaders receiving conflicting data split brain no way to resolve conflicting requests leader failure detection optimal timeout is tricky replication lag refers to the time it takes for writes on the leader to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the,,,,,,
right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the,can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make,to be reflected on all of the followers synchronous replication replication lag causes writes to be slower and the system to be more brittle as num followers increases asynchronous replication we maintain availability but at the cost of delayed or eventual consistency this delay is called the inconsistency window replication lag readafterwrite consistency scenario youre adding a comment to a reddit post after you click submit and are back at the main post your comment should show up for you less important for other users to see your comment as immediately implementing readafterwrite consistency method 1 modifiable data from the clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads,,,,,,
root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a,port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by,clients perspective is always read from the leader implementing readafterwrite consistency method 2 dynamically switch to reading from leader for recently updated data for example have a policy that all requests within one minute of last update come from leader but this can create its own challenges we created followers so they would be proximal to users but now we have to route requests to distant leaders when reading modifiable data monotonic read consistency monotonic read anomalies occur when a user reads values out of order from multiple followers monotonic read consistency ensures that when a user makes multiple reads they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with,,,,,,
way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history,they will not read older data after previously reading newer data consistent prefix reads reading data out of order can occur if different partitions replicate data at different rates there is no global write consistency consistent prefix read guarantee ensures that if a sequence of writes happens in a certain order anyone reading those writes will see them appear in the same order a b how far into the future can you see ms b about 10 seconds usually mr a ds 4300 nosql kv dbs mark fontenot phd northeastern university some material used with permission from dr rachlin with thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because,,,,,,
search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are,model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally,thanks distributed dbs and acid pessimistic concurrency acid transactions focuses on data safety considered a pessimistic concurrency model because it assumes one transaction has to protect itself from other transactions iow it assumes that if something can go wrong it will conflicts are prevented by locking resources until a transaction is complete there are both read and write locks write lock analogy borrowing a book from a library if you have it no one else can see httpswwwfreecodecamporgnewshowdatabasesguaranteeisolation for more for a deeper dive optimistic concurrency transactions do not obtain locks on data when they read or write optimistic because it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning,,,,,,
there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had,list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care,it assumes conflicts are unlikely to occur even if there is a conflict everything will still be ok but how add last update timestamp and version number columns to every table read them when changing then check at the end of transaction to see if any other transaction has caused them to be modified optimistic concurrency low conflict systems backups analytical dbs etc read heavy systems the conflicts that arise can be handled by rolling back and rerunning a transaction that notices a conflict so optimistic concurrency works well allows for higher concurrency high conflict systems rolling back and rerunning transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the,,,,,,
the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect,cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst,transactions that encounter a conflict less efficient so a locking scheme pessimistic model might be preferable nosql nosql first used in 1998 by carlo strozzi to describe his relational database system that did not use sql more common modern meaning is not only sql but sometimes thought of as nonrelational dbs idea originally developed in part as a response to processing unstructured webbased data httpswwwdataversitynetabriefhistoryofnonrelationaldatabases cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem you can have 2 but not 3 of the following consistency every user of the db has an identical view of the data at any given instant availability in the event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always,,,,,,
result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our,and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the,event of a failure the database system remains operational partition tolerance the database can maintain operations in the event of the networks failing between two segments of the distributed system note the definition of consistency in cap is different from that of acid cap theorem review reference httpsalperenbayramoglucompostsunderstandingcaptheorem consistency availability system always responds with the latest data and every request gets a response but may not be able to deal with network partitions consistency partition tolerance if system responds with data from the distrib system it is always the latest else data request is dropped availability partition tolerance system always sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems,,,,,,
own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in,care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential,sends are responds based on distributed store but may not be the absolute latest data acid alternative for distrib systems base basically available guarantees the availability of the data per cap but response can be failureunreliable because the data is in an inconsistent or changing state system appears to work most of the time acid alternative for distrib systems base soft state the state of the system could change over time even wo input changes could be result of eventual consistency data stores dont have to be writeconsistent replicas dont have to be mutually consistent acid alternative for distrib systems base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the,,,,,,
a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37,up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total,base eventual consistency the system will eventually become consistent all writes will eventually stop so all nodesreplicas can be updated categories of nosql dbs review first up keyvalue databases key value stores key value keyvalue stores are designed around simplicity the data model is extremely simple comparatively tables in a rdbms are very complex lends itself to simple crud ops and api creation key value stores key value keyvalue stores are designed around speed usually deployed as inmemory db retrieving a value given its key is typically a o1 op bc hash tables or similar data structs used under the hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model,,,,,,
31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are,require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection,hood no concept of complex queries or joins they slow things down key value stores key value keyvalue stores are designed around scalability horizontal scaling is simple add more nodes typically concerned with eventual consistency meaning in a distributed environment the only guarantee is that all nodes will eventually converge on the same value kv ds use cases edaexperimentation results store store intermediate results from data preprocessing and eda store experiment or testing ab results wo prod db feature store store frequently accessed feature lowlatency retrieval for model training and prediction model monitoring store key metrics about performance of model for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but,,,,,,
a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that,way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,for example in realtime inferencing kv swe use cases storing session information everything about the current session can be stored via a single put or post and retrieved with a single get very fast user profiles preferences user info could be obtained with a single get operation language tz product or ui preferences shopping cart data cart data is tied to the user needs to be available across browsers machines sessions caching layer in front of a diskbased database redis db redis remote directory server open source inmemory database sometimes called a data structure store primarily a kv store but can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually,,,,,,
this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search,binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be,can be used with other models graph spatial full text search vector time series from dbenginescom ranking of kv stores redis it is considered an inmemory database system but supports durability of data by a essentially saving snapshots to disk at specific intervals or b appendonly file which is a journal of changes that can be used for rollforward if there is a failure originally developed in 2009 in c can be very fast 100000 set ops second rich collection of commands does not handle complex data no secondary indexes only supports lookup by key redis data types keys usually strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make,,,,,,
tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done,is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would,strings but can be any binary sequence values strings lists linked lists sets unique unsorted string elements sorted sets hashes string string geospatial data setting up redis in docker in docker desktop search for redis pullrun the latest image see above optional settings add 6379 to ports to expose that port so we can connect to it normally you would not expose the redis port for security reasons if you did this in a prod environment major security hole notice we didnt set a password connecting from datagrip file new data source redis give the data source a name make sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial,,,,,,
recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is,seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics,sure the port is 6379 test the connection redis database and interaction redis provides 16 databases by default they are numbered 0 to 15 there is no other name associated direct interaction with redis is through a set of commands related to setting and getting kv pairs and variations many language libraries available as well foundation data type string sequence of bytes text serialized objects bin arrays simplest data type maps a string to another string use cases caching frequently accessed htmlcssjs fragments config settings user settings info token management counting web pageapp screen views or rate limiting some initial basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of,,,,,,
to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of,the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect,basic commands set pathtoresource 0 set user1 john doe get pathtoresource exists user1 del user1 keys user select 5 select a different database some basic commands set somevalue 0 incr somevalue increment by 1 incrby somevalue 10 increment by 10 decr somevalue decrement by 1 decrby somevalue 5 decrement by 5 incr parses the value as int and increments or adds to value setnx key value only sets value to key if key does not already exist hash type value of kv entry is a collection of fieldvalue pairs use cases can be used to represent basic objectsstructures number of fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history,,,,,,
the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be,maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is,fieldvalue pairs per hash is 2321 practical limit available system resources eg memory session information management userevent tracking could include ttl active session tracking all sessions under one hash key hash commands hset bike1 model demios brand ergonom price 1971 hget bike1 model hget bike1 price hgetall bike1 hmget bike1 model price weight hincrby bike1 price 100 what is returned list type value of kv pair is linked lists of string values use cases implementation of stacks and queues queue management message passing queues producerconsumer model logging systems easy to keep in chronological order build social media streamsfeeds message history in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs,,,,,,
olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have,purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees,in a chat application batch processing by queueing up a set of tasks to be executed sequentially at a later time linked lists crash course sequential data structure of linked nodes instead of contiguously allocated memory each node points to the next element of the list except the last one points to nilnull o1 to insert new value at front or insert new value at end 10 front back nil list commands queue queuelike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 rpop bikesrepairs rpop bilesrepairs list commands stack stacklike ops lpush bikesrepairs bike1 lpush bikesrepairs bike2 lpop bikesrepairs lpop bilesrepairs list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends,,,,,,
it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with,binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can,list commands others other list ops llen mylist lrange key start stop lrange mylist 0 3 lrange mylist 0 0 lrange mylist 2 1 lpush mylist one lpush mylist two lpush mylist three json type full support of the json standard uses jsonpath syntax for parsingnavigating a json document internally stored in binary in a treestructure fast access to sub elements set type unordered collection of unique strings members use cases track unique items ip addresses visiting a site page screen primitive relation set of all students in ds4300 access control lists for users and permission structures social network friends lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care,,,,,,
smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the,a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37,lists andor group membership supports set operations set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam sismember ds4300 mark sismember ds4300 nick scard ds4300 set commands sadd ds4300 mark sadd ds4300 sam sadd cs3200 nick sadd cs3200 sam scard ds4300 sinter ds4300 cs3200 sdiff ds4300 cs3200 srem ds4300 mark srandmember ds4300 31025 953 am ics 46 spring 2022 notes and examples avl trees ics 46 spring 2022 news course reference schedule project guide notes and examples reinforcement exercises grade calculator about alex ics 46 spring 2022 notes and examples avl trees why we must care about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6,,,,,,
relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering,about binary search tree balancing weve seen previously that the performance characteristics of binary search trees can vary rather wildly and that theyre mainly dependent on the shape of the tree with the height of the tree being the key determining factor by definition binary search trees restrict what keys are allowed to present in which nodes smaller keys have to be in left subtrees and larger keys in right subtrees but they specify no restriction on the trees shape meaning that both of these are perfectly legal binary search trees containing the keys 1 2 3 4 5 6 and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate,,,,,,
,node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember,and 7 yet while both of these are legal one is better than the other because the height of the first tree called a perfect binary tree is smaller than the height of the second called a degenerate tree these two shapes represent the two extremes the best and worst possible shapes for a binary search tree containing seven keys of course when all you have is a very small number of keys like this any shape will do but as the number of keys grows the distinction between these two tree shapes becomes increasingly vital whats more the degenerate shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the,,,,,,
,a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind,shape isnt even necessarily a rare edge case its what you get when you start with an empty tree and add keys that are already in order which is a surprisingly common scenario in realworld programs for example one very obvious algorithm for generating unique integer keys when all you care about is that theyre unique is to generate them sequentially whats so bad about a degenerate tree anyway just looking at a picture of a degenerate tree your intuition should already be telling you that something is amiss in particular if you tilt your head 45 degrees to the right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end,,,,,,
,this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search,right they look just like linked lists that perception is no accident as they behave like them too except that theyre more complicated to boot from a more analytical perspective there are three results that should give us pause every time you perform a lookup in a degenerate binary search tree it will take on time because its possible that youll have to reach every node in the tree before youre done as n grows this is a heavy burden to bear if you implement your lookup recursively you might also be using on memory too as you might end up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the,,,,,,
,how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty,up with as many as n frames on your runtime stack one for every recursive call there are ways to mitigate this for example some kinds of carefullywritten recursion in some programming languages including c can avoid runtime stack growth as you recurse but its still a sign of potential trouble the time it will take you to build the degenerate tree will also be prohibitive if you start with an empty binary search tree and add keys to it in order how long does it take to do it the first key you add will go directly to the root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total,,,,,,
,notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the,root you could think of this as taking a single step creating the node the second key you add will require you to look at the root node then take one step to the right you could think of this as taking two steps each subsequent key you add will require one more step than the one before it the total number of steps it would take to add n keys would be determined by the sum 1 2 3 n this sum which well see several times throughout this course is equal to nn 1 2 so the total number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a,,,,,,
,were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an,number of steps to build the entire tree would be θn2 overall when n gets large the tree would be hideously expensive to build and then every subsequent search would be painful as well so this in general is a situation we need to be sure to avoid or else we should probably consider a data structure other than a binary search tree the worst httpsicsucieduthorntonics46notesavltrees 17 31025 953 am ics 46 spring 2022 notes and examples avl trees case is simply too much of a burden to bear if n might get large but if we can find a way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be,,,,,,
,to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of,way to control the trees shape more carefully to force it to remain more balanced well be fine the question of course is how to do it and as importantly whether we can do it while keeping the cost low enough that it doesnt outweigh the benefit aiming for perfection the best goal for us to shoot for would be to maintain perfection in other words every time we insert a key into our binary search tree it would ideally still be a perfect binary tree in which case wed know that the height of the tree would always be θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary,,,,,,
,of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog,θlog n with a commensurate effect on performance however when we consider this goal a problem emerges almost immediately the following are all perfect binary trees by definition the perfect binary trees pictured above have 1 3 7 and 15 nodes respectively and are the only possible perfect shapes for binary trees with that number of nodes the problem though lies in the fact that there is no valid perfect binary tree with 2 nodes or with 4 5 6 8 9 10 11 12 13 or 14 nodes so generally its impossible for us to guarantee that a binary search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree,,,,,,
,search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of,search tree will always be perfect by our definition because theres simply no way to represent most numbers of keys so first things first well need to relax our definition of perfection to accommodate every possible number of keys we might want to store complete binary trees a somewhat more relaxed notion of perfection is something called a complete binary tree which is defined as follows a complete binary tree of height h is a binary tree where if h 0 its left and right subtrees are empty if h 0 one of two things is true the left subtree is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are,,,,,,
,work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one,is a perfect binary tree of height h 1 and the right subtree is a complete binary tree of height h 1 the left subtree is a complete binary tree of height h 1 and the right subtree is a perfect binary tree of height h 2 that can be a bit of a mindbending definition but it actually leads to a conceptually simple result on every level of a complete binary tree every node that could possibly be present will be except the last level might be missing nodes but if it is missing nodes the nodes that are there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would,,,,,,
,it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with,there will be as far to the left as possible the following are all complete binary trees furthermore these are the only possible complete binary trees with these numbers of nodes in them any other arrangement of say 6 keys besides the one shown above would violate the definition weve seen that the height of a perfect binary tree is θlog n its not a stretch to see that the height a complete binary tree will be θlog n as well and well accept that via our intuition for now and proceed all in all a complete binary tree would be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had,,,,,,
,1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh,be a great goal for us to attain if we could keep the shape of our binary search trees complete we would always have binary search trees with height θlog n the cost of maintaining completeness the trouble of course is that we need an algorithm for maintaining completeness and before we go to the trouble of trying to figure one out we should consider whether its even worth our time what can we deduce about the cost of maintaining completeness even if we havent figured out an algorithm yet one example demonstrates a very big problem suppose we had the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would,,,,,,
,at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change,the binary search tree on the left which is complete by our definition and we wanted to insert the key 1 into it if so we would need an algorithm that would transform the tree on the left into the tree on the right httpsicsucieduthorntonics46notesavltrees 27 31025 953 am ics 46 spring 2022 notes and examples avl trees the tree on the right is certainly complete so this would be the outcome wed want but consider what it would take to do it every key in the tree had to move so no matter what algorithm we used we would still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect,,,,,,
,avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,still have to move every key if there are n keys in the tree that would take ωn time moving n keys takes at least linear time even if you have the best possible algorithm for moving them the work still has to get done so in the worst case maintaining completeness after a single insertion requires ωn time unfortunately this is more time than we ought to be spending on maintaining balance this means well need to come up with a compromise as is often the case when we learn or design algorithms our willingness to tolerate an imperfect result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our,,,,,,
,,result thats still good enough for our uses will often lead to an algorithm that is much faster than one that achieves a perfect result so what would a good enough result be what is a good balance condition our overall goal is for lookups insertions and removals from a binary search tree to require olog n time in every case rather than letting them degrade to a worstcase behavior of on to do that we need to decide on a balance condition which is to say that we need to understand what shape is considered wellenough balanced for our purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our,,,,,,
,,purposes even if not perfect a good balance condition has two properties the height of a binary search tree meeting the condition is θlog n it takes olog n time to rebalance the tree on insertions and removals in other words it guarantees that the height of the tree is still logarithmic which will give us logarithmictime lookups and the time spent re balancing wont exceed the logarithmic time we would otherwise spend on an insertion or removal when the tree has logarithmic height the cost wont outweigh the benefit coming up with a balance condition like this on our own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees,,,,,,
,,own is a tall task but we can stand on the shoulders of the giants who came before us with the definition above helping to guide us toward an understanding of whether weve found what were looking for a compromise avl trees there are a few wellknown approaches for maintaining binary search trees in a state of nearbalance that meets our notion of a good balance condition one of them is called an avl tree which well explore here others which are outside the scope of this course include redblack trees which meet our definition of good and splay trees which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in,,,,,,
,,which dont always meet our definition of good but do meet it on an amortized basis but well stick with the one solution to the problem for now avl trees avl trees are what you might called nearly balanced binary search trees while they certainly arent as perfectlybalanced as possible they nonetheless achieve the goals weve decided on maintaining logarithmic height at no more than logarithmic cost so what makes a binary search tree nearly balanced enough to be considered an avl tree the core concept is embodied by something called the avl property we say that a node in a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty,,,,,,
,,a binary search tree has the avl property if the heights of its left and right subtrees differ by no more than 1 in other words we tolerate a certain amount of imbalance heights of subtrees can be slightly different but no more than that in hopes that we can more efficiently maintain it since were going to be comparing heights of subtrees theres one piece of background we need to consider recall that the height of a tree is the length of its longest path by definition the height of a tree with just a root node and empty subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37,,,,,,
,,subtrees would then be zero but what about a tree thats totally empty to maintain a clear pattern relative to other tree heights well say that the height of an empty tree is 1 this means that a node with say a childless left child and no right child would still be considered balanced this leads us finally to the definition of an avl tree an avl tree is a binary search tree in which all nodes have the avl property below are a few binary trees two of which are avl and two of which are not httpsicsucieduthorntonics46notesavltrees 37 31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every,,,,,,
,,31025 953 am ics 46 spring 2022 notes and examples avl trees the thing to keep in mind about avl is that its not a matter of squinting at a tree and deciding whether it looks balanced theres a precise definition and the two trees above that dont meet that definition fail to meet it because they each have at least one node marked in the diagrams by a dashed square that doesnt have the avl property avl trees by definition are required to meet the balance condition after every operation every time you insert or remove a key every node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are,,,,,,
,,node in the tree should have the avl property to meet that requirement we need to restructure the tree periodically essentially detecting and correcting imbalance whenever and wherever it happens to do that we need to rearrange the tree in ways that improve its shape without losing the essential ordering property of a binary search tree smaller keys toward the left larger ones toward the right rotations rebalancing of avl trees is achieved using what are called rotations which when used at the proper times efficiently improve the shape of the tree by altering a handful of pointers there are a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember,,,,,,
,,a few kinds of rotations we should first understand how they work then focus our attention on when to use them the first kind of rotation is called an ll rotation which takes the tree on the left and turns it into the tree on the right the circle with a and b written in them are each a single node containing a single key the triangles with t1 t2 and t3 written in them are arbitrary subtrees which may be empty or may contain any number of nodes but which are themselves binary search trees its important to remember that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that,,,,,,
,,that both of these trees before and after are binary search trees the rotation doesnt harm the ordering of the keys in nodes because the subtrees t1 t2 and t3 maintain the appropriate positions relative to the keys a and b all keys in t1 are smaller than a all keys in t2 are larger than a and smaller than b all keys in t3 are larger than b performing this rotation would be a simple matter of adjusting a few pointers notably a constant number of pointers no matter how many nodes are in the tree which means that this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an,,,,,,
,,this rotation would run in θ1 time bs parent would now point to a where it used to point to b as right child would now be b instead of the root of t2 bs left child would now be the root of t2 instead of a a second kind of rotation is an rr rotation which makes a similar adjustment note that an rr rotation is the mirror image of an ll rotation httpsicsucieduthorntonics46notesavltrees 47 31025 953 am ics 46 spring 2022 notes and examples avl trees a third kind of rotation is an lr rotation which makes an adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search,,,,,,
,,adjustment thats slightly more complicated an lr rotation requires five pointer updates instead of three but this is still a constant number of changes and runs in θ1 time finally there is an rl rotation which is the mirror image of an lr rotation once we understand the mechanics of how rotations work were one step closer to understanding avl trees but these rotations arent arbitrary theyre used specifically to correct imbalances that are detected after insertions or removals an insertion algorithm inserting a key into an avl tree starts out the same way as insertion into a binary search tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022,,,,,,
,,tree perform a lookup if you find the key already in the tree youre done because keys in a binary search tree must be unique when the lookup terminates without the key being found add a new node in the appropriate leaf position where the lookup ended the problem is that adding the new node introduced the possibility of an imbalance for example suppose we started with this avl tree and then we inserted the key 35 into it a binary search tree insertion would give us this as a result httpsicsucieduthorntonics46notesavltrees 57 31025 953 am ics 46 spring 2022 notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done,,,,,,
,,notes and examples avl trees but this resulting tree is not an avl tree because the node containing the key 40 does not have the avl property because the difference in the heights of its subtrees is 2 its left subtree has height 1 its right subtree which is empty has height 1 what can we do about it the answer lies in the following algorithm which we perform after the normal insertion process work your way back up the tree from the position where you just added a node this could be quite simple if the insertion was done recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the,,,,,,
,,recursively compare the heights of the left and right subtrees of each node when they differ by more than 1 choose a rotation that will fix the imbalance note that comparing the heights of the left and right subtrees would be quite expensive if you didnt already know what they were the solution to this problem is for each node to store its height ie the height of the subtree rooted there this can be cheaply updated after every insertion or removal as you unwind the recursion the rotation is chosen considering the two links along the path below the node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is,,,,,,
,,node where the imbalance is heading back down toward where you inserted a node if you were wondering where the names ll rr lr and rl come from this is the answer to that mystery if the two links are both to the left perform an ll rotation rooted where the imbalance is if the two links are both to the right perform an rr rotation rooted where the imbalance is if the first link is to the left and the second is to the right perform an lr rotation rooted where the imbalance is if the first link is to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is,,,,,,
,,to the right and the second is to the left perform an rl rotation rooted where the imbalance is it can be shown that any one of these rotations ll rr lr or rl will correct any imbalance brought on by inserting a key in this case wed perform an lr rotation the first two links leading from 40 down toward 35 are a left and a right rooted at 40 which would correct the imbalance and the tree would be rearranged to look like this compare this to the diagram describing an lr rotation the node containing 40 is c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of,,,,,,
,,c the node containing 30 is a the node containing 35 is b the empty left subtree of the node containing 30 is t1 the empty left subtree of the node containing 35 is t2 the empty right subtree of the node containing 35 is t3 the empty right subtree of the node containing 40 is t4 after the rotation we see what wed expect the node b which in our example contained 35 is now the root of the newlyrotated subtree the node a which in our example contained 30 is now the left child of the root of the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary,,,,,,
,,the newlyrotated subtree the node c which in our example contained 40 is now the right child of the root of the newlyrotated subtree the four subtrees t1 t2 t3 and t4 were all empty so they are still empty note too that the tree is more balanced after the rotation than it was before this is no accident a single rotation ll rr lr or rl is all thats necessary to correct an imbalance introduced by the insertion algorithm a removal algorithm removals are somewhat similar to insertions in the sense that you would start with the usual binary search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be,,,,,,
,,search tree removal algorithm then find and correct imbalances while the recursion unwinds the key difference is that removals can require more than one rotation to correct imbalances but will still only require rotations on the path back up to the root from where the removal occurred so generally olog n rotations asymptotic analysis the key question here is what is the height of an avl tree with n nodes if the answer is θlog n then we can be certain that lookups insertions and removals will take olog n time how can we be so sure lookups would be olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of,,,,,,
,,olog n because theyre the same as they are in a binary search tree that doesnt have the avl property if the height of the tree is θlog n lookups will run in olog n time insertions and removals despite being slightly more complicated in an avl tree do their work by traversing a single path in the tree potentially all the way down to a leaf position then all the way back up if the length of the longest path httpsicsucieduthorntonics46notesavltrees 67 31025 953 am ics 46 spring 2022 notes and examples avl trees thats what the height of a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have,,,,,,
,,a tree is is θlog n then we know that none of these paths is longer than that so insertions and removals will take olog n time so were left with that key question what is the height of an avl tree with n nodes if youre not curious you can feel free to just assume this if you want to know more keep reading what is the height of an avl tree with n nodes optional the answer revolves around noting how many nodes at minimum could be in a binary search tree of height n and still have it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum,,,,,,
,,it be an avl tree it turns out avl trees of height n 2 that have the minimum number of nodes in them all share a similar property the avl tree with height h 2 with the minimum number of nodes consists of a root node with two subtrees one of which is an avl tree with height h 1 with the minimum number of nodes the other of which is an avl tree with height h 2 with the minimum number of nodes given that observation we can write a recurrence that describes the number of nodes at minimum in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with,,,,,,
,,in an avl tree of height h m0 1 when height is 0 minimum number of nodes is 1 a root node with no children m1 2 when height is 1 minimum number of nodes is 2 a root node with one child and not the other mh 1 mh 1 mh 2 while the repeated substitution technique we learned previously isnt a good way to try to solve this particular recurrence we can prove something interesting quite easily we know for sure that avl trees with larger heights have a bigger minimum number of nodes than avl trees with smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is,,,,,,
,,smaller heights thats fairly selfexplanatory which means that we can be sure that 1 mh 1 mh 2 given that we can conclude the following mh 2mh 2 we can then use the repeated substitution technique to determine a lower bound for this recurrence mh 2mh 2 22mh 4 4mh 4 42mh 6 8mh 6 2jmh 2j we could prove this by induction on j but well accept it on faith let j h2 2h2mh h 2h2m0 mh 2h2 so weve shown that the minimum number of nodes that can be present in an avl tree of height h is at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the,,,,,,
,,at least 2h2 in reality its actually more than that but this gives us something useful to work with we can use this result to figure out what were really interested in which is the opposite what is the height of an avl tree with n nodes mh 2h2 log2mh h2 2 log2mh h finally we see that for avl trees of height h with the minimum number of nodes the height is no more than 2 log2n where n is the number of nodes in the tree for avl trees with more than the minimum number of nodes the relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change,,,,,,
,,relationship between the number of nodes and the height is even better though for reasons weve seen previously we know that the relationship between the number of nodes and the height of a binary tree can never be better than logarithmic so ultimately we see that the height of an avl tree with n nodes is θlog n in reality it turns out that the bound is lower than 2 log2n its something more akin to about 144 log2n even for avl trees with the minimum number of nodes though the proof of that is more involved and doesnt change the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,,,,,,
,,the asymptotic result httpsicsucieduthorntonics46notesavltrees 77,,,,,,
